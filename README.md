# External Data Monitor - Baseline Project

![Python](https://img.shields.io/badge/python-3.8+-blue.svg)
![Status](https://img.shields.io/badge/status-active-success.svg)
![Progress](https://img.shields.io/badge/progress-Mes%202%20(80%25)-yellow.svg)
![Commits](https://img.shields.io/github/commit-activity/w/CADIZza570/external-data-monitor)

Professional Python script that:
- Consumes public APIs (currently JSONPlaceholder /users)
- Validates data structure
- Saves results to timestamped CSV and JSON files
- Logs detailed execution and errors

## ğŸ“¸ Demo

### Successful execution:
```
ğŸš€ Iniciando api_data_fetcher.py â€“ Proyecto LÃ­nea Base (Mes 1-2)
[18:08:28] Conectando a la API...
âœ… Datos descargados: 10 registros
Validando estructura de datos...
âœ… ValidaciÃ³n exitosa

REPORTE DE LIMPIEZA (Mes 2)
- Registros originales: 10
- Registros limpios: 10
- Duplicados eliminados: 0
- Columnas seleccionadas: id, name, username, email, phone, website, city

âœ… CSV guardado: output/users_data_20251218_180828.csv
âœ… JSON guardado: output/users_data_20251218_180828.json
ğŸ‰ Script completado con Ã©xito
```

### Data analysis with groupby():
```
ğŸ“Š ANÃLISIS DE DATOS CON GROUPBY (Mes 2)
============================================================

1ï¸âƒ£ Usuarios por dominio de email:
email_domain
annie.ca       1
april.biz      1
elvis.io       1
...

ğŸ† Dominio mÃ¡s comÃºn: annie.ca (1 usuarios)

2ï¸âƒ£ Usuarios por ciudad:
city
Aliyaview         1
Bartholomebury    1
Gwenborough       1
...

âœ… AnÃ¡lisis completado
```

## Data Validation Logic

### Required fields
- **id:** Unique identifier required for tracking records
- **name:** Primary human-readable identifier
- **email:** Required for contact and system integrations
- **phone:** Required for potential outreach or CRM use

### Optional fields
- **address:** Not always needed depending on use case
- **website:** Informational only

### Discarded fields
- **company:** Removed to reduce noise and because it's not required for the current automation scope

Part of the **DEFINITIVE PLAN - Python + Automations (6 months)**  
Philosophy: Living systems that don't die.

## Installation

```bash
pip install pandas requests
```

## Dependencies

See `requirements.txt` for exact versions.

Install with:
```bash
pip install -r requirements.txt
```

## Usage

```bash
python api_data_fetcher.py
```

The script will:
1. Fetch data from JSONPlaceholder API
2. Validate required columns
3. Clean duplicates and normalize emails
4. Save timestamped outputs to `output/` directory
5. Log all operations to `api_data_fetcher.log`

### Data analysis:
```bash
python analyze_users.py
```

## Features

### Resilience (Mes 1 + Mes 4)
- âœ… Exponential backoff retry logic (1s, 2s, 4s)
- âœ… Handles 500, 502, 503, 504 server errors
- âœ… Timeout protection (10s max)
- âœ… Connection error handling

### Data Processing (Mes 2)
- âœ… Pandas data cleaning pipeline
- âœ… Duplicate removal by email
- âœ… Email normalization (lowercase)
- âœ… Email validation (contains @)
- âœ… City extraction from address
- âœ… Column selection and filtering

### Analysis (Mes 2)
- âœ… groupby() aggregations
- âœ… Multi-column statistics with .agg()
- âœ… Domain frequency analysis
- âœ… Geographic distribution

## Project Structure

```
python-automation/
â”œâ”€â”€ api_data_fetcher.py      # Main script with retry logic
â”œâ”€â”€ analyze_users.py          # Data analysis with groupby()
â”œâ”€â”€ test_manual.py            # Manual test suite
â”œâ”€â”€ requirements.txt          # Dependencies
â”œâ”€â”€ README.md                 # This file
â”œâ”€â”€ NOTES.md                  # Project journal and post-mortems
â””â”€â”€ output/                   # Generated files (not in Git)
    â”œâ”€â”€ users_data_*.csv
    â”œâ”€â”€ users_data_*.json
    â””â”€â”€ users_data_*_clean.csv
```

## ğŸ¯ Roadmap

### âœ… Completed (Mes 1-2):
- [x] Resilient API fetching with retry logic
- [x] Data validation and cleaning with Pandas
- [x] Professional logging and error handling
- [x] Automated duplicate removal
- [x] Email normalization and validation
- [x] Data analysis with groupby()
- [x] City extraction from nested JSON

### ğŸŸ¡ In Progress (Mes 3):
- [ ] n8n workflow integration
- [ ] Webhook endpoints
- [ ] Email alerts on errors
- [ ] Multi-source data aggregation

### â³ Planned (Mes 4-6):
- [ ] Niche validation (Columbus, OH market)
- [ ] Client-ready maintenance package ($30-50/month)
- [ ] Production deployment with monitoring
- [ ] Excel file support (read_excel)
- [ ] Data merging from multiple sources

### Mes 3 - Ejecuciones automÃ¡ticas (Python + schedule)
- El script ahora corre como daemon local.
- Intervalo actual: cada 10 minutos (para pruebas).
- PrÃ³ximo: migraciÃ³n a cron en servidor real.
- Control total: sin dependencias externas.

Usage daemon:
```bash
python3 api_data_fetcher.py

## Progress Status

**Current:** Mes 2 (80% complete) - 5-6 weeks ahead of schedule  
**Next milestone:** n8n basic workflow (Mes 3)  
**Timeline:** Started Dec 17, 2025

## Contributing

This is a learning project following the "Definitive Plan - Python + Automations (6 months)".  
Philosophy: Systems that don't die. Action > Perfection.

## License

Personal learning project - Not licensed for commercial use yet.

---

**Part of:** [DEFINITIVE PLAN - Python + Automations (6 months)](PLAN.md)  
**Author:** Constanza Araya  
**Location:** Columbus, Ohio, US

# ğŸš€ Webhook Automation System â€“ Shopify (MVP)

## ğŸ“Œ DescripciÃ³n general

Sistema de automatizaciÃ³n en Python que recibe webhooks (simulados o reales), procesa datos de productos, genera diagnÃ³sticos automÃ¡ticos y guarda evidencia en archivos CSV.

Este proyecto estÃ¡ diseÃ±ado bajo la filosofÃ­a de **sistemas vivos, mantenibles y vendibles**, enfocado en automatizaciones reales para eâ€‘commerce.

---

## ğŸ§  QuÃ© hace el sistema

* Recibe webhooks vÃ­a **Flask** (`POST`)
* Procesa payloads tipo Shopify
* Convierte datos a `DataFrame`
* Ejecuta diagnÃ³sticos automÃ¡ticos:

  * ğŸ“‰ Stock bajo
  * ğŸ’¤ Productos sin ventas
  * âš ï¸ Datos faltantes
* Guarda resultados en CSV auditables
* Devuelve respuesta HTTP clara

---

## ğŸ—‚ï¸ Estructura del proyecto

```
tu_proyecto/
â”‚
â”œâ”€â”€ webhook_server.py        # Servidor Flask (entrada principal)
â”œâ”€â”€ config.py                # ConfiguraciÃ³n global (thresholds, paths)
â”‚
â”œâ”€â”€ fetchers/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ fetchers.py          # Ingesta de datos (local / APIs)
â”‚
â”œâ”€â”€ alerts/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ alerts.py            # LÃ³gica de alertas
â”‚
â”œâ”€â”€ diagnostics/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ diagnostics.py       # Limpieza, validaciÃ³n y guardado
â”‚
â”œâ”€â”€ output/                  # Evidencia generada (CSV)
â”‚
â”œâ”€â”€ logs/                    # Logs de ejecuciÃ³n
â””â”€â”€ README.md
```

---

## â–¶ï¸ CÃ³mo ejecutar el servidor

Desde la carpeta del proyecto:

```bash
python3 webhook_server.py
```

Servidor disponible en:

```
http://127.0.0.1:5001
```

---

## ğŸ§ª CÃ³mo probar (simulaciÃ³n Shopify)

```bash
curl -X POST http://127.0.0.1:5001/webhook/shopify \
-H "Content-Type: application/json" \
-d '{
  "products": [
    {
      "title": "Camiseta Roja",
      "variants": [
        {
          "id": 101,
          "title": "S",
          "inventory_quantity": 3,
          "last_sold_date": "2025-12-10"
        }
      ]
    }
  ]
}'
```

---

## ğŸ“‚ Resultados esperados

DespuÃ©s de una llamada exitosa:

* `output/shopify_webhook_*.csv`
* `output/low_stock_*.csv`
* `output/no_sales_*.csv`

Estos archivos son **evidencia directa** del diagnÃ³stico.

---

## ğŸ§± Estado del proyecto

* âœ… MVP funcional
* âœ… Arquitectura modular
* âœ… Listo para integraciÃ³n real con Shopify
* âœ… Automatizable con cron / schedule

---

## ğŸš€ PrÃ³ximos pasos

1. Conectar Shopify real (API + Webhooks oficiales)
2. Automatizar ejecuciÃ³n con `cron` o `schedule`
3. Agregar notificaciones (email / Slack)
4. Empaquetar como servicio vendible

---
# Python Automation: Shopify Webhook & CSV Alerts

## DescripciÃ³n
Proyecto de automatizaciÃ³n en Python para:
- Recibir webhooks de Shopify (productos, stock, ventas).
- Generar alertas de bajo stock o sin ventas.
- Crear CSV de reportes y registros histÃ³ricos.
- IntegraciÃ³n segura usando `.env` para variables de configuraciÃ³n.

Se enfoca en **Python puro + cron/schedule** para sistemas mantenibles.

---

## Estructura del proyecto



## ğŸ‘¤ Autor

Gonzalo Diaz â€“ AutomatizaciÃ³n & Sistemas Python
